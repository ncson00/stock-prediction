{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "from datetime import datetime, timedelta\n",
    "import argparse\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "import pickle\n",
    "\n",
    "from math import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from db.postgres import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "PG_USER = \"postgres\"\n",
    "PG_PASSWORD = \"1\"\n",
    "PG_DATABASE = \"stock\"\n",
    "PG_HOST = \"172.18.0.3\"\n",
    "PG_PORT = 5432\n",
    "PG_DRIVER = 'org.postgresql.Driver'\n",
    "\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2023-02-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    def __init__(self, ticket, lookback = 60):\n",
    "        self.ticket = ticket\n",
    "        self.lookback = lookback\n",
    "\n",
    "\n",
    "    def get_scaler(self):\n",
    "        df = psql.read_sql(f\"select date, close from stock_raw where stock = '{self.ticket}'\", connect())\n",
    "        dataset = df[['close']].values\n",
    "\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "        return scaler\n",
    "\n",
    "\n",
    "    def model_input(self):\n",
    "\n",
    "        self.get_scaler()\n",
    "\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(self.dataset) - self.lookback):\n",
    "            row = [a for a in self.dataset[i:i+self.lookback]]\n",
    "            dataX.append(row)\n",
    "            dataY.append(self.dataset[i + self.lookback][0])\n",
    "\n",
    "        X, y = np.array(dataX), np.array(dataY)\n",
    "\n",
    "        # Train-test split\n",
    "        split_point = int(len(self.dataset)*0.9)\n",
    "        X_train, y_train = X[:split_point], y[:split_point]\n",
    "        X_val, y_val = X[split_point:len(X)], y[split_point:len(y)]\n",
    "\n",
    "        return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ticket):\n",
    "    return pickle.load(open(f'model/LTSM_{ticket}.sav', 'rb'))\n",
    "\n",
    "def update_rmse(ticket, run_date):\n",
    "\n",
    "    '''\n",
    "    '''\n",
    "    model = DataHandler(ticket=ticket, lookback=60)\n",
    "\n",
    "    X_train, y_train, X_val, y_val = model.preprocess()\n",
    "\n",
    "    ltsm = load_model(ticket)\n",
    "    y_predict = ltsm.predict(X_val)\n",
    "\n",
    "    scaler = model.get_scaler()\n",
    "    predict_price = scaler.inverse_transform(y_predict.reshape(-1, 1))\n",
    "    true_price = scaler.inverse_transform(y_val.reshape(-1, 1))\n",
    "\n",
    "    rmse = sqrt(mean_squared_error(true_price, predict_price))\n",
    "\n",
    "    postgres_operator(\n",
    "        query=f\"\"\"\n",
    "            delete from rmse where date = '{run_date}';\n",
    "            insert into rmse values ({run_date}, {ticket}, {rmse});\n",
    "        \"\"\",\n",
    "        conn=connect()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
